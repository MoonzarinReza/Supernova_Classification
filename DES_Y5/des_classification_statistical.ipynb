{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DES Classifictaion Using Statistical Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "from astropy.table import Table, join, column, Column\n",
    "import astropy\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.colors as colors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import  precision_score, recall_score, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from numpy import std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight = 0.800, Loss = 53.189, Time = 21.16s\n",
      "weight = 1.200, Loss = 53.568, Time = 42.22s\n",
      "Accuracy:\n",
      "0.8859649122807017\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# --- Load data ---\n",
    "df_train = pd.read_csv(\"train_data.csv\")\n",
    "df_test = pd.read_csv(\"des_test_data2.csv\")\n",
    "\n",
    "\n",
    "unc_features_cols = ['g_err_mag', 'r_err_mag', 'i_err_mag', 'z_err_mag', \n",
    "'g_err_alpha', 'g_err_beta', 'r_err_alpha', 'r_err_beta',\n",
    "'i_err_alpha', 'i_err_beta','z_err_alpha', 'z_err_beta']\n",
    "\n",
    "features_cols = [\n",
    "    'g_pk_mag','r_pk_mag', 'i_pk_mag', 'z_pk_mag', \n",
    "    'g_alpha', 'g_beta', 'r_alpha', 'r_beta', 'i_alpha', 'i_beta',\n",
    "    'z_alpha', 'z_beta'\n",
    "]\n",
    "label_col = 'type'\n",
    "\n",
    "tfeatures = df_train[features_cols].values\n",
    "etfeatures = df_train[unc_features_cols].values\n",
    "SNT = df_train[\"type\"].values\n",
    "\n",
    "# --- Preprocessing ---\n",
    "invalid = (tfeatures <= -999) | (etfeatures <= 0.0001)\n",
    "for k in range(tfeatures.shape[1]):\n",
    "    valid_idx = ~invalid[:, k]\n",
    "    if np.any(valid_idx):\n",
    "        median_feat = np.median(tfeatures[valid_idx, k])\n",
    "        median_unc = np.median(etfeatures[valid_idx, k]) * 240.\n",
    "        tfeatures[~valid_idx, k] = median_feat\n",
    "        etfeatures[~valid_idx, k] = median_unc\n",
    "\n",
    "wa = np.where(SNT == \"SN Ia\")[0]\n",
    "wb = np.where(SNT != \"SN Ia\")[0]\n",
    "tfeaturesa = tfeatures[wa]\n",
    "etfeaturesa = etfeatures[wa]\n",
    "tfeaturesb = tfeatures[wb]\n",
    "etfeaturesb = etfeatures[wb]\n",
    "etfeatures[:, 0:5] = np.sqrt(etfeatures[:, 0:5]**2 + 0.05**2)\n",
    "\n",
    "na = len(wa)\n",
    "nb = len(wb)\n",
    "\n",
    "features = df_test[features_cols].values\n",
    "efeatures = df_test[unc_features_cols].values\n",
    "SNTtest = df_test[\"type\"].values\n",
    "efeatures[:, 0:5] = np.sqrt(efeatures[:, 0:5]**2 + 0.05**2)\n",
    "\n",
    "features1 = df_test[features_cols].values\n",
    "efeatures1 = df_test[unc_features_cols].values\n",
    "\n",
    "invalid_test1 = (features1 <= -999) | (efeatures1 <= 0.0001)\n",
    "features1[invalid_test1] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "invalid_test = (features <= -999) | (efeatures <= 0.0001)\n",
    "features[invalid_test] = 9.99\n",
    "efeatures[invalid_test] = 1e13\n",
    "\n",
    "# --- PA function ---\n",
    "def PA(a, features, efeatures, tfeaturesa, etfeaturesa, na, tfeaturesb, etfeaturesb, nb):\n",
    "    lnpa = np.array([\n",
    "        -0.5 * (np.sum((tfeaturesa[i] - features)**2 / (etfeaturesa[i]**2 + efeatures**2)) +\n",
    "                np.sum(np.log(etfeaturesa[i]**2 + efeatures**2)))\n",
    "        for i in range(na)\n",
    "    ])\n",
    "\n",
    "    \n",
    "\n",
    "    lnpb = np.array([\n",
    "        -0.5 * (np.sum((tfeaturesb[i] - features)**2 / (etfeaturesb[i]**2 + efeatures**2)) +\n",
    "                np.sum(np.log(etfeaturesb[i]**2 + efeatures**2)))\n",
    "        for i in range(nb)\n",
    "    ])\n",
    "    mln = max(np.max(lnpa), np.max(lnpb))\n",
    "    # lnpa -= mln\n",
    "    # lnpb -= mln\n",
    "    wa = lnpa > -700\n",
    "    wb = lnpb > -700\n",
    "\n",
    "\n",
    "    pa = np.sum(np.exp(lnpa[wa])) if np.any(wa) else 0\n",
    "    pb = np.sum(np.exp(lnpb[wb])) if np.any(wb) else 0\n",
    "    if not np.any(wa) and not np.any(wb):\n",
    "        return 0.5\n",
    "    if pa == 0 and pb == 0 or nb == 0:\n",
    "        raise RuntimeError(\"Invalid PA computation\")\n",
    "    return pa / (pa + a * na / nb * pb)\n",
    "\n",
    "# --- Optimization ---\n",
    "naiter = 1\n",
    "mina = 0.8\n",
    "maxa = 1.2\n",
    "\n",
    "#a_vals=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]\n",
    "a_vals = np.linspace(mina, maxa, naiter+1)\n",
    "PASN = np.zeros((naiter+1, len(SNTtest)))\n",
    "loss = np.zeros(naiter+1)\n",
    "\n",
    "wa_test = np.where(SNTtest == 1)[0]\n",
    "wb_test = np.where(SNTtest != 1)[0]\n",
    "\n",
    "t0 = time.time()\n",
    "for ia, a in enumerate(a_vals):\n",
    "    for i in range(len(SNTtest)):\n",
    "        PASN[ia, i] = PA(a, features[i], efeatures[i], tfeaturesa, etfeaturesa, na, tfeaturesb, etfeaturesb, nb)\n",
    "    loss[ia] = np.sum(1.0 - PASN[ia, wa_test]) + np.sum(PASN[ia, wb_test])\n",
    "    print(f\"weight = {a:.3f}, Loss = {loss[ia]:.3f}, Time = {time.time() - t0:.2f}s\")\n",
    "\n",
    "\n",
    "\n",
    "a_loss_array = np.column_stack((a_vals, loss))\n",
    "\n",
    "# Save only a_loss array\n",
    "#np.savez(\"PSN0.01_aloss.npz\", a_loss=a_loss_array)\n",
    "df_results = pd.DataFrame(a_loss_array, columns=[\"a\", \"loss\"])\n",
    "\n",
    "\n",
    "wx = np.argmin(loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "yy=len([x for x in PASN[wx, wa_test] if x > 0.5])+len([x for x in PASN[wx, wb_test] if x < 0.5])\n",
    "print('Accuracy:')\n",
    "print( yy/(len(PASN[wx, wa_test])+len(PASN[wx, wb_test])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
